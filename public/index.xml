<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R Statistics for Ecologists on Documentation for Hugo Learn Theme</title>
    <link>/</link>
    <description>Recent content in R Statistics for Ecologists on Documentation for Hugo Learn Theme</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 24 Oct 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>R Studio &amp; Coding Environment</title>
      <link>/introduction-to-r/01_r-studio-and-the-coding-environment/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/introduction-to-r/01_r-studio-and-the-coding-environment/</guid>
      <description>IntroductionThis module will provide an introduction into the R statisitical environment, going through the basics of data analysis and graphing for publication quality results.By the end of this module, you should be able to:
Understand and use the R studio working environmentImport and manipulate data filesUndertake linear (ANOVA, regression) and generalised linear (logistic regression) models and associated assumptions/comparisonsUndertake basic multivariate techniques (PCA, MDS)Construct bar plots and scatterplots in ggplotWhat is R?</description>
    </item>
    
    <item>
      <title>Packages</title>
      <link>/data-exploration-and-manipulation/1_packages/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/data-exploration-and-manipulation/1_packages/</guid>
      <description>#Data Exploration &amp;amp; Manipulation#
####PackagesNow that you have setup your R environment and read in your first data set, we can begin to modify and add to our data as necessary.
Now for the majority of this module, we will be working with a package called Tidyverse. Packages are collections of data, R functions and complied code to add extra features outside of the general base R environment. Packages are central to expanding the possibilities of R.</description>
    </item>
    
    <item>
      <title>Setting up your workspace</title>
      <link>/introduction-to-r/02_setting-up-your-workspace/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/introduction-to-r/02_setting-up-your-workspace/</guid>
      <description>There are very quick ways to open R and begin coding, however, having an organised, well-structured working directory in your computer can save you hours of hassle and make your code much easier to share. As biology and data science are becoming increasingly complex many are turning to computer intensive, coding based software (like you!). With this movement in data science and open access, having our code reproducible, transparent and understandable is key.</description>
    </item>
    
    <item>
      <title>Columns</title>
      <link>/data-exploration-and-manipulation/2_columns/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/data-exploration-and-manipulation/2_columns/</guid>
      <description>2) Changing ColumnsAnother important aspect of R coding syntax is refering to specific columns. This is done by using a $ sign after specifying our dataset and then calling the column. Like so:
head(weeds$flowers.m3) # This says to run the head() command but only on the flowers.m3 column## [1] 14 17 23 26 35 45Try this with some of the other commands above. Note: Some of them will not work and will show NULL.</description>
    </item>
    
    <item>
      <title>Creating a project and notebook</title>
      <link>/introduction-to-r/03_creating-a-project-and-notebook/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/introduction-to-r/03_creating-a-project-and-notebook/</guid>
      <description>Now that we have our folder setup, lets move into R studio and create our project.
The first step when opening a new R studio environment is creating a script or notebook for working in. Scripts are basic text files where all code is executable. Writing non-code in a script requires the use of #’s (which can look messy and confusing) like so:
read.csv(&amp;quot;datafile.csv&amp;quot;) # this code reads a csv (data) file into R.</description>
    </item>
    
    <item>
      <title>Importing Data</title>
      <link>/introduction-to-r/04_importing-data/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/introduction-to-r/04_importing-data/</guid>
      <description>Now that we have successfully have a notebook and appropriate working directory, we can start to read in data.
The first thing with R is that working with normal excel files is quite difficult. So we always work with comma separated values or .CSV files. When saving an excel sheet, just save as and select .csv (comma delimited) as the file type. note: .csv’s can only save a single sheet, not the whole excel workbook</description>
    </item>
    
    <item>
      <title>Manipulating data part 1</title>
      <link>/data-exploration-and-manipulation/3_manipulatingp1/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/data-exploration-and-manipulation/3_manipulatingp1/</guid>
      <description>3) Manipulating data with TidyverseAs previously mentioned, one of the extremely useful and time saving parts of R is manipulating your data without touching your original spreadsheet.
This can be done with the base R language (everything we have done so far) or with packages in the Tidyverse library, such as “dplyr” and “tidyr”. These simplify the language of coding and offer useful tools for data manipulation.
Make sure you have loaded tidyverse with the library() command before attempting any functions.</description>
    </item>
    
    <item>
      <title>Manipulating data part 2</title>
      <link>/data-exploration-and-manipulation/4_manipulatingp2/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/data-exploration-and-manipulation/4_manipulatingp2/</guid>
      <description>The Select FunctionThis is used to select specific columns within your data and save them as a new data frame. You can use this if you have a large dataset and only want to use a few of the columns, to keep it simple and tidy. Or, you may want to take a column or two from multiple different datasets and combine them.
weeds_select &amp;lt;- select(weeds, soil) # select one column, &amp;quot;soil&amp;quot;weeds_select &amp;lt;- select(weeds,c(soil, species)) # select two columns, &amp;quot;soil&amp;quot; and &amp;quot;species&amp;quot;weeds_select &amp;lt;- select(weeds,c(2:4)) # select columns using numbers.</description>
    </item>
    
    <item>
      <title>Analysis of Variance</title>
      <link>/statistical-analysis/1_aov/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/statistical-analysis/1_aov/</guid>
      <description>1. Analysis of Variance (ANOVA)To begin our foray into statistics in R, we will start with the most basic and most useful analysis, Analysis of Variance (ANOVA). An ANOVA is used to test the effect of 1 or more categorical explanatory variables (X) on a continuous response variable (Y). The ANOVA tests the difference between the factors variance (distance from the grand mean) compared to the error variance. The variance for each point is squared and added together to generate the sum of squares, which is then used to generate the F ratio.</description>
    </item>
    
    <item>
      <title>Manipulating data part 3</title>
      <link>/data-exploration-and-manipulation/5_manipulatingp3/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/data-exploration-and-manipulation/5_manipulatingp3/</guid>
      <description>Removing ItemsBy now, we have quite a few objects in our R environment that aren’t being used. The remove() command does exactly that….removes objects from the R environment. This helps for making things nice and tidy, specifically in our environment window.
remove(frogfull, froginner, enviro_filter) # Removes all three objects we just generatedUse this in the console to “one off” remove an item.
The Summarise FunctionThis is an extremely useful function that lets you create different summaries of columns.</description>
    </item>
    
    <item>
      <title>ANOVA assumptions</title>
      <link>/statistical-analysis/2_aovassumptions/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/statistical-analysis/2_aovassumptions/</guid>
      <description>2. Assumptions of an ANOVANormality: Normality can be tested in two basic ways. Through visual inspection of residuals in a normal quantile (QQ) plot and histogram, OR, through a mathematical test such as a shapiro-wilks test.
To produce the two graphs for visual inspection of residuals we use the following commands:
plot(weeds.aov, 2) # Normal quantile plotThe normal qq plot should display the residuals along the dotted line in a straight manner.</description>
    </item>
    
    <item>
      <title>The Grammer of Graphics - Plotting your data with ggplot!</title>
      <link>/the-grammar-of-graphics/grammar-of-graphics/</link>
      <pubDate>Sun, 21 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/the-grammar-of-graphics/grammar-of-graphics/</guid>
      <description>ResourcesThe Grammar of ggplotBasic plotsCustomising your graphGrids and BackgroundAxis LinesPanel lines/gridsLabelsA Proper examplePlotting our analysed dataWeeds (ANOVA bar graph)Tadpoles (linear regression)Nest Dataset (Logistic Regression/GLM)By now you should be fairly familiar with the R environment and decently familiar with tidyverse. You should be able to perform basic data manipulations, analyses and in general, understand the general concepts of working with data in R.</description>
    </item>
    
    <item>
      <title>ANOVA Results</title>
      <link>/statistical-analysis/3_anovaresults/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/statistical-analysis/3_anovaresults/</guid>
      <description>3. ResultsOnce we know our data is normal and we have our aov() object, we can use one of two commands on this object to generate our statistical result. The normal way to do so is to use the anova() command.
anova(weeds.aov) # run an anova on the object## Analysis of Variance Table## ## Response: flowers## Df Sum Sq Mean Sq F value Pr(&amp;gt;F) ## species 2 2368.</description>
    </item>
    
    <item>
      <title>Two-factor Analysis of Variance</title>
      <link>/statistical-analysis/4_twofactors/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/statistical-analysis/4_twofactors/</guid>
      <description>4. Two-factors and TransformationsTo conduct an two-factor ANOVA is pretty straightforward.
weeds.aov2 &amp;lt;- aov(flowers ~ species + soil, data = weeds) # two-factor anova (without interaction)summary(weeds.aov2)## Df Sum Sq Mean Sq F value Pr(&amp;gt;F) ## species 2 2369 1184.3 9.272 0.000436 ***## soil 1 239 238.5 1.867 0.178720 ## Residuals 44 5620 127.7 ## ---## Signif. codes: 0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.</description>
    </item>
    
    <item>
      <title>Tukeys HSD</title>
      <link>/statistical-analysis/5_tukeys/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/statistical-analysis/5_tukeys/</guid>
      <description>5. Tukey’s HSDAll of our analyses so far have showed us that species has an influence on flower abundance. But without conducting an extra test, we cannot be certain which species are statistically significant from each other when it comes to their effect on flower abundance
TukeyHSD(weeds.aov) ## Tukey multiple comparisons of means## 95% family-wise confidence level## ## Fit: aov(formula = flowers ~ species, data = weeds)## ## $species## diff lwr upr p adj## Olearia-Coprosma 12.</description>
    </item>
    
    <item>
      <title>Linear Regression</title>
      <link>/statistical-analysis/6_linearregession/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/statistical-analysis/6_linearregession/</guid>
      <description>6. Linear RegressionLinear regression is one of the most highly used statistical techniques in all of life and earth sciences. It is used to model the relationship between a response (Y) variable and a explanatory (X) variable. A linear regression is a special case of a linear model whereby both the response and explanatory variables are continuous. The ANOVA we just conducted is still considered as a linear model since the response variable is a linear (additive) combination of the effects of the explanatory variables.</description>
    </item>
    
    <item>
      <title>ANOVA assumptions</title>
      <link>/statistical-analysis/7_glms/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/statistical-analysis/7_glms/</guid>
      <description>7. Generalised Linear Models (GLMs)So far, we have been using linear models which assume that our response variable is continuous. In earth and life sciences (ecology in particular) we are often working with discrete data, such as count data and binomial (presence/absence) data.
The linear models we have been using so far have been assuming a normal (or gaussian) distribution in our data. Generalised linear models (GLMs) allow us to fit alternative distributions to our data in order to more accurately analyse them.</description>
    </item>
    
    <item>
      <title></title>
      <link>/datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/datasets/</guid>
      <description>  Data Sets   frog_environmental.csv  (2 ko)   frogs.csv  (1 ko)   insecticide.csv  (0 ko)   nestpredation.csv  (0 ko)   site.csv  (0 ko)   tadpoles.csv  (0 ko)   weeds.csv  (1 ko)    </description>
    </item>
    
  </channel>
</rss>