[
{
	"uri": "/introduction-to-r/",
	"title": "Introduction to R",
	"tags": [],
	"description": "",
	"content": " Introduction to R Setting up your working environment in R studio\n"
},
{
	"uri": "/introduction-to-r/01_r-studio-and-the-coding-environment/",
	"title": "R Studio &amp; Coding Environment",
	"tags": [],
	"description": "",
	"content": "Introduction\rThis module will provide an introduction into the R statisitical environment, going through the basics of data analysis and graphing for publication quality results.\rBy the end of this module, you should be able to:\n\rUnderstand and use the R studio working environment\rImport and manipulate data files\rUndertake linear (ANOVA, regression) and generalised linear (logistic regression) models and associated assumptions/comparisons\rUndertake basic multivariate techniques (PCA, MDS)\rConstruct bar plots and scatterplots in ggplot\r\rWhat is R?\rR is a language and environment for statistical computing and graphics. R is free/open source software and as a result, has a community of dedicated statisticans, coders and developers increasing the capabilities and usability of the platform.\rR primarily runs as a command-line program.\nThis is a big entry barrier to many starting to learn R, so most people have turned to “R Studio”.\nBase R\n\r\rWhy R?\rSince R is free and open source, it is a program and skill that can be carried with you across many institutions and jobs and is for many, the single solution for statistical analysis, graphing and even GIS/spatial analysis. Programs like JMP, SPSS and ARCGIS cost 100s if not 1000s of dollars and are quickly outdated by new versions.\nHowever, the biggest uses of R come from its sharability and openness. Collaborating and sharing data analysis with R requires only the script and raw data. All data manipulations are done within R, requiring no editing or manipulating of your raw excel data.\n\rR Studio\rThe R Studio Environment\n\rR studio “reskins” the standard R environment, giving space for script writing, help, graphics output and tracking of data files. Due to the ease of working in R studio, thats what we will be using. R studio can provide an array of functions from statistical analysis and graphing, GIS/spatial analysis, presentations, document preparation (all of these tutorials are written in R) and even novel functions like interacive graphs and tweeting.\n\rLayout\rR studio is separated into 4 panels:\n\rThe top-left panel (blue) is the editor (or script window) where you can view and write your R script. This is a saveable document of code. Running code is as simple as Ctrl+Enter on a line of code or pressing the run button in the top-right of this window.\n\rThe bottom-left (red) is the console. This is the standard R environment where you can run code directly, or view the output of your script as you run it.\n\rThe top-right (green) is your workspace. This lists each “object” as you create them through your analyses. Clicking a data-frame object will allow you to view it.\n\rThe bottom-left (black) has lists of files and packages as well as the help window (quickly access by typing ? before any command) and plots which shows any graphical output.\n\r\rNow we have an idea of what R is, it is time to install R \u0026amp; R Studio onto your computer.\nInstall Instructions\n1. Click Here to visit the R webpage and select one of the Australian mirrors to download (CSIRO, University of Melbourne etc.)\n2. Select your version (Windows or Mac), then download the base subdirectory\n3. Once installed, visit R studio to download R studio desktop.\n Once both of those are installed, you can now proceed to open up Rstudio\n\r\r"
},
{
	"uri": "/data-exploration-and-manipulation/",
	"title": "Data Exploration and Manipulation",
	"tags": [],
	"description": "",
	"content": " Chapter 1 Data Exploration and Manipulation Exploring data in its native format and manipulating it using Tidyverse\n"
},
{
	"uri": "/data-exploration-and-manipulation/1_packages/",
	"title": "Packages",
	"tags": [],
	"description": "",
	"content": "#Data Exploration \u0026amp; Manipulation#\n####Packages\rNow that you have setup your R environment and read in your first data set, we can begin to modify and add to our data as necessary.\nNow for the majority of this module, we will be working with a package called Tidyverse. Packages are collections of data, R functions and complied code to add extra features outside of the general base R environment. Packages are central to expanding the possibilities of R. The ability to do advanced graphing, GIS, complicated analyses, multivariate analyses etc. are all due to contributed packages. Tidyverse is a unique case as it is a collection of R packages that all use similar coding syntax\n####To install a package into R there are two options:\nOption 1 is to select the packages tab in the help/viewer window \u0026amp; click the install button.\nThen type the package name in the packages box (note: ensure that it is installing from Repository/CRAN)\nOption 2 is to use the following code, replacing the “tidyverse” with the package of your choice. This should be used in the console, rather than the script window as you only need to install the package once.\ninstall.packages(\u0026quot;tidyverse\u0026quot;)\rOnce you have installed tidyverse, simply load it into your current workspace with the following command (in your script)\nlibrary(tidyverse)\rIn general, it is good practice to place the library() commands for your whole document at the top before anything else. This allows people reading your code to load in any packages they will need at the beginning before anything else.\rFor example, here is the first few lines of one of my own scripts:\nThis shows the reader of my code what packages need to be installed to run my analysis. I also write notes to myself to remind myself what specific packages are for. Once you start accumulating packages, its hard to remember what each one does. I find this particularly useful for packages I only use for a particular function (such as the agricolae package which I use for tukeys letter reports).\nWrite Ok in the following box to continue:\r{1:SHORTANSWER:=Ok}\n"
},
{
	"uri": "/introduction-to-r/02_setting-up-your-workspace/",
	"title": "Setting up your workspace",
	"tags": [],
	"description": "",
	"content": "There are very quick ways to open R and begin coding, however, having an organised, well-structured working directory in your computer can save you hours of hassle and make your code much easier to share. As biology and data science are becoming increasingly complex many are turning to computer intensive, coding based software (like you!). With this movement in data science and open access, having our code reproducible, transparent and understandable is key. So why not start off like that.\nThe first part of this tutorial follows many practices outlined in the fantastic “Guide to Reproducible Code in Ecology and Evolution” from the British Ecological Society. I strongly recommend reading this at some stage.\n File system\rBefore we jump into R, we are going to create a clean and managable folder system.\rCreate a new folder in a location of your choosing (e.g. My Documents or Desktop) called R-tutorials\n This can be named anything you like, but try to keep it relevant and understandable (for future you).\nIn this new folder, create a series of new folders called:\n- data\n- doc\n- figs\n- output\n- R\n Here is the basic outline for these folders:\n\r\rThe data folder if where you store your raw/input data\r\r\rThe doc folder is where you store the manuscript for the project\r\r\rThe figs folder is where all of your figures will be stored from the analyses\r\r\rThe output folder is where you keep any intermediate datasets generated by your analysis, result reports etc.\r\r\rThe R folder is pretty self-explanatory but it is where we will store all of our R scripts, notebooks etc.\r\r\rNow, let’s move on to the next step.\n\r"
},
{
	"uri": "/data-exploration-and-manipulation/2_columns/",
	"title": "Columns",
	"tags": [],
	"description": "",
	"content": "2) Changing Columns\rAnother important aspect of R coding syntax is refering to specific columns. This is done by using a $ sign after specifying our dataset and then calling the column. Like so:\nhead(weeds$flowers.m3) # This says to run the head() command but only on the flowers.m3 column\r## [1] 14 17 23 26 35 45\rTry this with some of the other commands above. Note: Some of them will not work and will show NULL. This is because these are designed to view aspects of the data frame (e.g. names() )\nNow we know how to refer to a column, we can fix any issues with importing incorrect data\n# Pretend for a moment our data was input incorrectly\rweeds$species\u0026lt;-factor(weeds$species) # this would simply save the command factor() on the column species to our weeds object.\r# If we wanted an ordered factor, e.g. small \u0026lt; medium \u0026lt; large we can use the following\r#example dataset\rsizes \u0026lt;- factor(c(\u0026quot;small\u0026quot;, \u0026quot;large\u0026quot;, \u0026quot;large\u0026quot;, \u0026quot;small\u0026quot;, \u0026quot;medium\u0026quot;, \u0026quot;medium\u0026quot;)) # creating a single column factor with 3 levels\rsizes\r## [1] small large large small medium medium\r## Levels: large medium small\rsizes \u0026lt;- ordered(sizes, levels = c(\u0026quot;small\u0026quot;, \u0026quot;medium\u0026quot;, \u0026quot;large\u0026quot;)) # ordering levels from small through to large.\r# Note: I did not need to specify column as this is a single column dataset. sizes # Now the factor is ordered.\r## [1] small large large small medium medium\r## Levels: small \u0026lt; medium \u0026lt; large\rweeds$species\u0026lt;-ordered(weeds$species, levels=c(\u0026quot;Pultenaea\u0026quot;, \u0026quot;Olearia\u0026quot;, \u0026quot;Coprosma\u0026quot;)) # This is an example with our data set, but this is nonsensical ordering so dont do this\rBy default, R will always sort in alphabetical order, which can be a pain when graphing. If you want ordered factors, or want to present factors along an X axis in a more logical order then the ordered() command or even factor() command where you specify levels is a good option.\nIf you want to change something to a continuous (numeric, integer etc.) its a little more complicated, but in general R shouldn’t mess this up too often. A quick google search or ?numeric will help answer this.\nOnce we can reference to specific columns we can do interesting things like plot a quick graph.\nplot(weeds$flowers.m3 ~ weeds$soil) # This says to plot a graph with flowers.m3 by (~) soil. \r# You should get a box and whisker plot. hist(weeds$flowers.m3) # hist() is a command that only works on numeric (continuous) columns, and will show you a histogram\rTry replacing the column names in the plot() command to see what types of graphs you get. We will return to graphing at a later date, but this is a quick and easy way to view your data.\nUsing the plot() command with the insecticide dataset answer the following question:\nQuestion: What fragment size has a species richness outlier? (according to the box \u0026amp; whisker plot)\n{1:SHORTANSWER: =Small}\n\r"
},
{
	"uri": "/introduction-to-r/03_creating-a-project-and-notebook/",
	"title": "Creating a project and notebook",
	"tags": [],
	"description": "",
	"content": "Now that we have our folder setup, lets move into R studio and create our project.\nThe first step when opening a new R studio environment is creating a script or notebook for working in. Scripts are basic text files where all code is executable. Writing non-code in a script requires the use of #’s (which can look messy and confusing) like so:\nread.csv(\u0026quot;datafile.csv\u0026quot;) # this code reads a csv (data) file into R. The command read.csv requires brackets with the filepath to the file in quotations. # in this code, none of the #\u0026#39;s will run. so if I # the read.csv command, it will not run. like so:\r# read.csv(\u0026quot;datafile.csv\u0026quot;)\rA whole document of the above example can get messy and hard to understand.\nIn a notebook, we separate normal text from code by inserting “code chunks” (insert \u0026gt; R in the top right of the window). Chunks are specialised areas in the notebook for code only.\rChunks separate code from text, making it easier to write notes and read. These tutorials have been written in a notebook.\n To create a notebook or script, simply use the pulldown menus file \u0026gt; new file and select either a script or notebook one. Then save the document by hitting the disk icon (or file \u0026gt; save) R studio will prompt you to install some packages to use a notebook. Do so and then read the text in the notebook then clear everything below the “output:” — area. As stated above, click the insert pulldown menu in the script window and click R to insert a code chunk. All code in a notebook must be written in a chunk   IMPORTANT!\r\rWherever you save the notebook/script will become the default “directory”. R will look here for files first. If you want to set your working directory elsewhere, use the below code.\n\rI advise creating a folder and saving the notebook to the folder. All datafiles for these pracs can be placed in the same folder as your script/notebook. This will simplify the process of reading in data.\r\r# Only do this if you want your notebook/script in a different folder from data\rsetwd(\u0026quot;Drive:/Folder1/Folder2\u0026quot;)\r# insert your folders path in the brackets\r# this will tell R to look here for files and \u0026quot;generally\u0026quot; save things here as well.\r# e.g. C:/Users/Mitch/Documents/R/\r\rAfter writing your code, you can click run, run selected line(s), run current chunk or press Ctrl + Enter on the line your cursor is on\n\rGet used to this, you will do this ALOT\n\r"
},
{
	"uri": "/introduction-to-r/04_importing-data/",
	"title": "Importing Data",
	"tags": [],
	"description": "",
	"content": "Now that we have successfully have a notebook and appropriate working directory, we can start to read in data.\nThe first thing with R is that working with normal excel files is quite difficult. So we always work with comma separated values or .CSV files. When saving an excel sheet, just save as and select .csv (comma delimited) as the file type. note: .csv’s can only save a single sheet, not the whole excel workbook\nWhen saving, Excel will inform you that some features may not save with a .csv. This shouldn’t be a problem for you, but read these to make sure.\nImporting our data into R allows us to not only analyse and graph the data, but do manipulations, like create new columns using formulae, rearranging, rename and even removing columns \u0026amp; rows without modifying our original data file. This is incredibly useful to maintain the original raw data, allowing you to share the data and R script with collaborators across a wide range of platforms.\nFor these tutorials, all data will be csv files (unless otherwise specified).\nDownload the “weeds” and “insecticide” datasets from the Datasets tab and save them to your project folder.\n Use the following code within a chunk to enter your data into R:\nread.csv(\u0026quot;weeds.csv\u0026quot;)\rThe file needs to be in your set working directory. If it is not, you need the full filepath. You can skip the working directory step by using the full file path. e.g. “C:/Users/Mitch/Documents/R/weeds.csv”\nThis can be copied from file explorer, but make sure the slash’s are / and not\n This alone will just read the data in its basic form into R. If we want to call on this later we need to save the datafile or “data frame” to a variable of our choosing. By saving different functions in R to a variable/object we reduce the amount of work we need to do later. Instead of typing “group_data_2018_complete.csv” everytime, we can instead just call it “data”, “X” or even “skittles” and type that when we refer to the data.\nI personally would choose something a little more descriptive than just “data”, as it can get confusing when working with multiple data sets\nAssigning a function in R to a variable is one of the most important aspects of coding in R.\n This is done by the following:\nweeds \u0026lt;- read.csv(\u0026#39;weeds.csv\u0026#39;)\r# we simply direct our command, read.csv() to our variable name using an arrow of \u0026lt; and -\r# alternatively, \u0026#39;alt\u0026#39; + \u0026#39;-\u0026#39; is the shortcut for this. \rR will automatically assume that the first row are our column headings. The read.csv() command has this by default. If you want to change this, simply include the header=FALSE argument (like below). Arguments are anything within the brackets of a command that can be added to the command. Even stating your filename in the read.csv is an “argument”\nSimilarly, read.csv() defaults its own row numbers (like excel). You can change this by adding row.names= to the command. If you add =1 it will take the first column as your row numbers/names.\nweeds \u0026lt;- read.csv(\u0026#39;weeds.csv\u0026#39;, header=FALSE) # this will stop the automatic placement of your first row as your column headers. The default for this is TRUE\rweeds \u0026lt;- read.csv(\u0026#39;weeds.csv\u0026#39;, row.names=1) # This places your first column as your row names. Change the number to make a different column your row names\r# This is useful to place site names/numbers as your row numbers. It is basically required when trying to do multivariate (PRIMER) analysis in R.\r# You can combine the two just by adding a comma between them, like so:\rweeds \u0026lt;- read.csv(\u0026#39;weeds.csv\u0026#39;, header=TRUE, row.names=1)\r# we want the first row to be our column names, so we say TRUE for header. # You dont need to do this, as its an assumed default by R...but its good practice\r# For these workshops we will be using R\u0026#39;s default row numbering. So just overwrite your read.csv() without the row.names\rweeds \u0026lt;- read.csv(\u0026#39;weeds.csv\u0026#39;, header=TRUE)\rOnce your data is imported into R and saved as an object, either click the object in the Workspace/environment or use View(weeds)\nWhat is the argument of read.csv() I would need to use to make the sites column my row names?\n ## sites type\r## 1 WAM5 plan\r## 2 WBT1 iso\r## 3 WBT2 rem\r## 4 WBT4 rip\r## 5 WCS2 rip\r## 6 WCS3 iso\r  Answer   row.names=1\nfull command: read.csv(\u0026quot;sitedata.csv\u0026quot;, row.names=1)\n "
},
{
	"uri": "/data-exploration-and-manipulation/3_manipulatingp1/",
	"title": "Manipulating data part 1",
	"tags": [],
	"description": "",
	"content": "3) Manipulating data with Tidyverse\rAs previously mentioned, one of the extremely useful and time saving parts of R is manipulating your data without touching your original spreadsheet.\nThis can be done with the base R language (everything we have done so far) or with packages in the Tidyverse library, such as “dplyr” and “tidyr”. These simplify the language of coding and offer useful tools for data manipulation.\nMake sure you have loaded tidyverse with the library() command before attempting any functions.\nFor the rest of the course from here on out, there will be many arguments (parts) of functions that will be left out. If you want to learn about other customisation options for your code, or are lost at any point, use the “Help” tab in R studio or type “?” followed by the name of the function.\re.g. ?rename.\nOtherwise, the internet is a awesome resource for R help.\nThe Rename Function\rBy now, if you are like me, you are probably getting annoyed at writing “flowers.m3” or “species.richness” everytime you need to refer to one of those columns. This will happen ALOT with data you enter or obtain from others, as R converts any spaces to fullstops. The rename() function allows us to simply rename a column name within our data frame. Personally, this is my favourite function in R as I hate captials, fullstops and other annoying column name problems.\nTo do this with dplyr (a tidyverse package) we simply use the following command:\nweeds \u0026lt;- rename(weeds, flowers = flowers.m3)\r# In the brackets we need to specify our data frame (weeds) followed by a second argument specifying the name we want for our column = the name we already have.\r# Again, if you run this by itself it will not save to your data frame, unless you direct it to your data frame variable using the \u0026lt;- \rPretty simple and straightforward.\n\rThe Mutate Function\rOne of the most common data manipulations is adding a new column to your dataset. This is great for transforming data, while also keeping the original. This could be used to combine multiple columns into one or perform mathematical calculations involving multiple columns with the results in a separate column.\nWe will start out with a few simple methods in base R, and then move to the dplyr method.\n##Log Transformation##\rweeds$log_flowers \u0026lt;- log(weeds$flowers) # Base R\rweeds \u0026lt;- mutate(weeds, log_flowers = log(flowers)) # Dplyr\r# Each of these creates a new column which is the log of the flowers column.\r## Basic math functions##\rweeds_mutate \u0026lt;- mutate(weeds, flowers2 = flowers*2) # Simple multiplication of the flowers column by 2\rweeds_mutate \u0026lt;- mutate(weeds, flowers_combined = flowers + flowers2) # This is a useless example but its just to show you how to combine multiple columns. weeds_mutate \u0026lt;- mutate(data, binary = soil == \u0026quot;sandstone\u0026quot;) # Using boolean logic to create a column called \u0026quot;binary\u0026quot; where soil is exactly (hence double =\u0026#39;s) sandstone. weeds_mutate \u0026lt;- mutate(data, flowers2 = flowers*2,\rbinary = soil == \u0026quot;sandstone\u0026quot;) # You can also perform the functions multiple times on the same data within one line. \rThe arguments of mutate() are simply the name of the data frame followed by any number of expressions that create new variables.\nYou will notice throughout the mutate() commands that we have performed functions, creating new columns, while preserving the original. If you wish to drop the original column, simply use the transmute() command.\nUse the Mutate() command on the insecticide dataset to answer the following question\nQuestion: What is the square of the number in the last row of species.richness (row 42)?\n{1:SHORTANSWER:=255}\n\rThe Filter Function\rThe filter() command is used to remove rows from your data. This can be useful for removing zeros or “no data/NA’s”, or for restricting certain variables in a dataset for an analysis.\nThis follows the similar syntax as mutate() whereby we specify what dataset we want to filter, followed by how we want to filter.\n#The following examples will just keep overwriting the new object \u0026quot;weeds_filtered\u0026quot;\rweeds_filtered \u0026lt;- filter(weeds, weeds == \u0026quot;native\u0026quot;) # Gives us only the rows which are exactly \u0026quot;native\u0026quot; in the weeds column. weeds_filtered \u0026lt;- filter(weeds, weeds != \u0026quot;weed\u0026quot;) # This gives us the same result as their are only two levels of that column. The != means \u0026quot;not equal to\u0026quot;\rweeds_filtered \u0026lt;- filter(weeds ,flowers \u0026gt; 20) # Flowers greater than 20 m3\rSo far, we have covered renaming columns, adding new columns and filtering by rows. The next two commands are focused on selecting specific columns and creating new data tables.\nWrite Ok in the following box to continue:\n{1:SHORTANSWER:=Ok}\n\r\r"
},
{
	"uri": "/data-exploration-and-manipulation/4_manipulatingp2/",
	"title": "Manipulating data part 2",
	"tags": [],
	"description": "",
	"content": "The Select Function\rThis is used to select specific columns within your data and save them as a new data frame. You can use this if you have a large dataset and only want to use a few of the columns, to keep it simple and tidy. Or, you may want to take a column or two from multiple different datasets and combine them.\nweeds_select \u0026lt;- select(weeds, soil) # select one column, \u0026quot;soil\u0026quot;\rweeds_select \u0026lt;- select(weeds,c(soil, species)) # select two columns, \u0026quot;soil\u0026quot; and \u0026quot;species\u0026quot;\rweeds_select \u0026lt;- select(weeds,c(2:4)) # select columns using numbers. In this case, select columns 2 through to 4.\rweeds_select \u0026lt;- select(weeds, c(soil:flowers)) # select columns \u0026quot;soil\u0026quot; through to \u0026quot;flowers\u0026quot;\rweeds_select \u0026lt;- select(weeds, -soil) # remove \u0026quot;soil\u0026quot;\r# similar syntax applys for removing columns, just place a - infront e.g. select(weeds, -c(2:4))\rweeds_select \u0026lt;- select(weeds, starts_with(\u0026quot;s\u0026quot;)) # select any column whose name starts with S. # there are many more like this above example, like \u0026quot;ends_with\u0026quot;, \u0026quot;contains\u0026quot; and \u0026quot;matches\u0026quot; all which refer to the column names # use the help window (?select) for more useful functions with select()\r\rCombining data sets\rOne of the most frequent data manipulations for working within R is joining multiple data sets together. The most common example of this is combining species abundance (or some other variable of interest) with external sources on the environmental conditions, such as BOM data (temperature, precipitation etc.) or GPS data.\nTo do most statistical analyses, data needs to be in the same data frame. So joining the datasets is an “easy” way to do so outside of excel.\nFor this exercise, we will be working with the BIOL365 Frog Data to combine the species matrix with environmental data\nDownload the “frogs.csv” and “frog_environmental.csv”\u0026quot; files and read them in to R without the row.names command\nfrogsp\u0026lt;-read.csv(\u0026quot;frogs.csv\u0026quot;, header=TRUE)\renviro\u0026lt;-read.csv(\u0026quot;frog_environmental.csv\u0026quot;, header=TRUE)\r# For a complete combine of both datasets, when there are the same number of rows in the same order\rfrogcombine \u0026lt;- bind_cols(frogsp, enviro) # In this example the \u0026quot;site\u0026quot; column has been added twice\r# There is a bind_rows() that will add rows to the bottom of a dataset, using the same syntax\rfrogjoin \u0026lt;- left_join(frogsp, enviro, by=\u0026quot;Site\u0026quot;) # This will join two datasets by a similar column (Site). # This will join the second dataset (enviro) to the first data set based on the shared column. right_join() will do the opposite\r# We can use the dim() to view the dimensions of the data\rdim(frogsp) # 11 columns\r## [1] 42 11\rdim(enviro) # 16 columns\r## [1] 42 16\rdim(frogjoin) # 26 colums (11 + 16 minus the 1 in common)\r## [1] 42 26\rBoth of these examples so far have required the same rows for each dataset. Sometimes we might have more information in one dataset then we do in the other. For this dataset we don’t have this issue, so lets quickly create the issue to demonstrate.\nWe will simply use the filter() command to filter for rows that contain a value in the “Temp” column. We have 4 rows that have an NA in “Temp” so we will use a != (not equal to) to select all rows that are not equal to NA\nenviro_filter \u0026lt;- filter(enviro, Temp != \u0026quot;NA\u0026quot;) # This removes sites 14, 15, 35 \u0026amp; 36\rdim(enviro_filter)\r## [1] 38 16\r# Now we can try the two new join types\rfroginner \u0026lt;- inner_join(frogsp, enviro_filter, by=\u0026quot;Site\u0026quot;) # Join data. Retain only rows that occur in both data sets\rdim(froginner) # 38 rows\r## [1] 38 26\rfrogfull \u0026lt;- full_join(frogsp, enviro_filter, by=\u0026quot;Site\u0026quot;) # Join data. Retain all values, all rows\rdim(frogfull)\r## [1] 42 26\rYou can also use semi_join() to combine all rows that have a match in the second dataset, or anti_join() to combine all rows that do not match have a match in the second dataset (this ones a little weird).\nWrite Ok in the following box to continue:\n{1:SHORTANSWER:=Ok}\n\r"
},
{
	"uri": "/statistical-analysis/",
	"title": "Statistical Analysis",
	"tags": [],
	"description": "",
	"content": " Chapter 2 Statistical Analysis Text here\n"
},
{
	"uri": "/statistical-analysis/1_aov/",
	"title": "Analysis of Variance",
	"tags": [],
	"description": "",
	"content": "1. Analysis of Variance (ANOVA)\rTo begin our foray into statistics in R, we will start with the most basic and most useful analysis, Analysis of Variance (ANOVA). An ANOVA is used to test the effect of 1 or more categorical explanatory variables (X) on a continuous response variable (Y). The ANOVA tests the difference between the factors variance (distance from the grand mean) compared to the error variance. The variance for each point is squared and added together to generate the sum of squares, which is then used to generate the F ratio. The F ratio is then compared to a critical value from a table of values (based of degrees of freedom) to determine the level of significance, or P value.\nIn this module, we will be using a variety of datasets to test each analysis. These will be specified in each section before the code chunk in bold.\nFor this analysis, we will be using the weeds dataset.\nTo begin the analysis, we need to create an ANOVA object using the aov() command. This will tell any summary(), plot() or other commands that the object is specifically for an ANOVA and as such, will be treated as one.\nThe syntax for almost all analyses in R is the same. Within our analysis command (aov() in this example) we write a line equation for our analysis:\ny ~ x\nThis is simply your response variable (Y) and explanatory variable(s) (X) separated by a tilde ~. The tilde acts as an = sign for the analysis.\nweeds.aov \u0026lt;- aov(flowers ~ species, data=weeds) # flowers (Y variable) ~ species (X variable), then data = weeds to direct it to our dataframe. # call your object what ever you want, but I tend to name it something to remind me of the dataset/analysis as well as the statistical technique. \rNow we have our aov() object, it is good practice to test the assumptions before we look at the results of the analysis. Having this workflow in place will hopefully prevent you from “forgetting” assumptions after seeing a significant result.\nWrite Ok in the following box to continue:\n{1:SHORTANSWER:=Ok}\n\r"
},
{
	"uri": "/data-exploration-and-manipulation/5_manipulatingp3/",
	"title": "Manipulating data part 3",
	"tags": [],
	"description": "",
	"content": "Removing Items\rBy now, we have quite a few objects in our R environment that aren’t being used. The remove() command does exactly that….removes objects from the R environment. This helps for making things nice and tidy, specifically in our environment window.\nremove(frogfull, froginner, enviro_filter) # Removes all three objects we just generated\rUse this in the console to “one off” remove an item.\n\rThe Summarise Function\rThis is an extremely useful function that lets you create different summaries of columns. You can also nest other functions within it to apply them to your columns.\nsum_data \u0026lt;- summarise(weeds, mean(flowers)) # We\u0026#39;ll start simple. Generates the mean of the flower column\rsum_data \u0026lt;- summarise(group_by(weeds, species), mean(flowers)) # Using the group_by() function within summarise lets you get summaries for groups, in this case \u0026quot;species\u0026quot;\rsum_data \u0026lt;- summarise(group_by(weeds,species, soil), mean(flowers), sd(flowers), se=sd(flowers/sqrt(n())))\r# Grouped by with species \u0026amp; soil, generating mean, standard deviation \u0026amp; standard error of flowers\rThe last example generates the mean, sd and se for each factor combination in our dataset. This is pretty useful, particularly for generating bar graphs.\nHowever, its a little complex and can be in a much nicer format.\nUse the summarise() function on the insecticide dataset to answer the following question\rQuestion: In the large fragment, what is the median species richness\n{1:SHORTANSWER:=12}\n\rThe Pipe Function\rThis lets you run multiple different functions on one dataset without having to use the intermediate steps you would have to use in base R.\nYou start with the data you want to apply the functions to, followed by a pipe %\u0026gt;%. After each pipe you must go to the next line.\nThis is useful for large messy functions with multiple nested parts. It separates everything out and makes it easier to follow.\nA pipe is simply a \u0026gt; nested within two percentage, %, symbols. The keyboard shortcut for this is Ctrl + SHIFT + M\nsum_data \u0026lt;- weeds %\u0026gt;% group_by(species, soil) %\u0026gt;% summarise(max(flowers))\r# You start with the data you want to apply the functions to, followed by a pipe. After each pipe you must go to the next line # In this example, we grouped the data by species and soil, then performed the summarise function to generate the max number for each combination\rnew_data \u0026lt;- weeds %\u0026gt;% mutate(binary = soil == \u0026quot;sandstone\u0026quot;) %\u0026gt;% filter(weeds == \u0026quot;native\u0026quot;)\r# As you can see, we can do this with most of the stuff we have already learnt\r# This will generate a binary outcome (true/false) for soil with TRUE as \u0026quot;sandstone\u0026quot;. Followed by filtering for \u0026quot;native\u0026quot; weeds\rPiping is incredibly useful and much easier to read.\nYou will notice, that because we specified the data in the first line, we did not have to specify the data in the other lines, only the columns\nWrite finished in the following box to continue:\n{1:SHORTANSWER:=finished}\n\r"
},
{
	"uri": "/statistical-analysis/2_aovassumptions/",
	"title": "ANOVA assumptions",
	"tags": [],
	"description": "",
	"content": "2. Assumptions of an ANOVA\rNormality: Normality can be tested in two basic ways. Through visual inspection of residuals in a normal quantile (QQ) plot and histogram, OR, through a mathematical test such as a shapiro-wilks test.\nTo produce the two graphs for visual inspection of residuals we use the following commands:\nplot(weeds.aov, 2) # Normal quantile plot\rThe normal qq plot should display the residuals along the dotted line in a straight manner. In this example, it is pretty straight :)\nPlotting the aov() object will generate 4 plots. The QQ plot is the second, so we can just specify the second one to avoid the other 3.\nTry removing the 2 and comma and see what the plot command does on its own. It does this because it is being applied to a statistical object (i.e. aov() ).\nNOTE: The plot command (without specifying 1-4) may require you to press “ENTER” in the console for each plot. Look in the console after running this command\nWe can also produce a histogram of the residuals:\nhist(weeds.aov$residuals) # Histogram of residuals\rTo produce a histogram of the residuals, we simply need to specify the residuals column of our aov() object. Simple!\nThe reason this works is because the aov() object contains its own column for residuals (amongst other things). Try running str() on weeds.aov to see what columns it contains. The second one should be the residuals.\nSomething “fun” to do, is to combine both of the graphs in the same window. This produces the same style of output we would get in JMP.\n## This may not work in a default notebook ##\rpar(mfrow = c(1,2)) # This code put two plots in the same window\rhist(weeds.aov$residuals)\rplot(weeds.aov, 2)\r# If your using a notebook, the par() command wont work. ## Click the settings cog and select \u0026quot;chunk output in console\u0026quot;\r# If your future graphs keep using this two plot window, use the following command in the console to stop it.\r# dev.off()\rRunning a shapiro-wilks test is a similar story. To produce a shapiro-wilks test requires the following code:\nshapiro.test(weeds.aov$residuals) # run a shapiro-wilks test on the residuals column of our anova object using the shapiro.test() function\r## ## Shapiro-Wilk normality test\r## ## data: weeds.aov$residuals\r## W = 0.98282, p-value = 0.6993\rWith a shapiro-wilks test, if the result is significant, this means our data is NOT-NORMAL. In our case our data is normal.\nWhat is the shapiro-wilks p-value for an anova of species richness and fragment in the Insecticide dataset\n{1:SHORTANSWER:=0.01113}\nHomogeneity of Variance: Homogeneity of variance is the other main assumption we are concerned with when conducting an ANOVA. Homogeneity of variance is the assumption that the variance between groups is relatively even. That is to say, all groups have similar variation between them. Similar to the assumption of normality, there are two ways to test homogeneity, a visual inspection of residuals and a statistical test.\nTo conduct a visual inspection of the residuals we simply use the following:\nplot(weeds.aov, 1) # using plot number 1 this time\rHeterogenous variances are indicated by a non-random pattern in the residuals vs fitted plot. We look for an even spread of residuals along the Y axis for each of the levels in the X axis. We know species contains 3 levels (“Comprosma”, “Oleria” \u0026amp; “Pultenaea”) so we should see three columns of dots, with an even spread along the Y axis.\nThe other way to test this is to use a statistical test, such as a Cochrans or Bartletts test. For this module, we will be taking a departure from the typical Cochran’s Test as there are other tests that (in my personal opinion) are more useful and WAY easier to conduct in R. The first of these will be a Bartlett’s test.\nbartlett.test(flowers ~ species, data = weeds)\r## ## Bartlett test of homogeneity of variances\r## ## data: flowers by species\r## Bartlett\u0026#39;s K-squared = 0.15957, df = 2, p-value = 0.9233\rSimple and easy!\nThis shows us that the variances are homogenous (i.e. a non-significant P value). The reason we may not use a Bartlett’s test all of the time is because it is highly sensitive to departures from normality (i.e. non-normal datasets). If we suspect our data is not-normal or is slightly not-normal and want to test homogeneity of variance anyways, we can use a Levene’s Test to account for this. I suggest reading up on the differences between bartlett’s and levene’s tests before using levene’s. Here is how to do it anyway:\nlibrary(car) # install the car package for this test\rleveneTest(flowers ~ species, data=weeds)\r## Levene\u0026#39;s Test for Homogeneity of Variance (center = median)\r## Df F value Pr(\u0026gt;F)\r## group 2 0.3131 0.7327\r## 45\rAgain, simple and easy to use. Our P value is not significant which agrees with the Bartlett’s test result.\nWhat is the bartlett p-value for the species richness by fragment analysis in the Insecticide dataset\n{1:SHORTANSWER:=0.1022}\n\r"
},
{
	"uri": "/the-grammar-of-graphics/grammar-of-graphics/",
	"title": "The Grammer of Graphics - Plotting your data with ggplot!",
	"tags": ["ggplot"],
	"description": "",
	"content": "\rResources\rThe Grammar of ggplot\rBasic plots\r\rCustomising your graph\rGrids and Background\rAxis Lines\rPanel lines/grids\rLabels\rA Proper example\r\rPlotting our analysed data\rWeeds (ANOVA bar graph)\rTadpoles (linear regression)\rNest Dataset (Logistic Regression/GLM)\r\r\r\rBy now you should be fairly familiar with the R environment and decently familiar with tidyverse. You should be able to perform basic data manipulations, analyses and in general, understand the general concepts of working with data in R.\nTo me personally, graphing is the funnest part of statistics. Being able to visually communicate your findings in new and interesting ways is exciting and a joy when you have so many ways to customise your message. Data analysis is important and useful, but the fun part is definately graphing.\nFor this module, we will be working soley within the ggplot graphing environment. Before we start, I should mention - R does have its own plotting functions which are powerful and very useful.\nGGPLOT is just better :)\nTo start, we will cover the bases of what ggplot is and how to build basic graphs with some free data built into R.\nResources\rHere are a few websites and useful places for ggplot graphing help. Its great to see examples of graphs along with code to help.\n\rGGPLOT CHEATSHEET - Seriously, this is amazing. There are a few of these on R studios’ website for a bunch of packages. I have a few of these printed on the wall of my office. Additonally, many of these can be accessed in the Help toolbar next to tools\rGGPLOT Reference Site - The official ggplot help site\n\rData Carpentry’s ggplot guide\n\rR Graphics Cookbook - Useful guides for graphing\r\rWrite Ok in the following box to continue:\n{1:SHORTANSWER:=Ok}\n\rThe Grammar of ggplot\rggplot is one of the many packages installed with tidyverse, but is important package on its own, that can be installed by itself library(ggplot2).\nGGplot was built as a way to implement Leland Wilkinson’s “Grammar of Graphics”. The gammar of graphics broke up data visualisation into semantic components such as scales, layers and various aesthetic features. GGplot is a implementation of this scheme into the R environment.and its crazy powerful.\nFirst, make sure ggplot2 or tidyverse is installed and loaded using the library() command.\nOnce we have that loaded into our environment, we need to create our first plot window following this basic structure.\nplot1 \u0026lt;- ggplot(data, aes(x = variable, y = variable)) +\rgeom_graph.type()\rplot1 # to view our object\rWe begin by creating a new object/variable of our choosing like almost everything else we do. We then use the ggplot() function to build a blank plot window.\nThe aes argument specifies what variables we want to plot in our blank window. aes stands for aesthetics, which is slightly confusing because it relates to what data we are displaying.not how we display it.\nThe + geom_graph.type() will be the type of graph you want to display. the commonly used examples are:\n\rboxplot - + geom_boxplot()\rbarplot - + geom_bar()\rscatterplot - + geom_point()\r\rGeom stands for geometric, and tells R the type of geometric shape you want the data to form. You will need () closed brackets at the end of the geom_type() regardless of whether you choose to put anything inside them.\nThe next important thing is the use of additive building in ggplot. As you can see in the example, we use a + sign before adding the geom_type we want. Everything in ggplot uses these additive steps before each function. This allows you to add and change things on your graph step by step, building and viewing your graph as you go. This will make more sense as we go.\nWrite Ok in the following box to continue:\r{1:SHORTANSWER:=Ok}\nBasic plots\rTo start, we will use the iris dataset that is built into tidyverse/ggplot2. To view the dataset, use the View() command like so:\nView(iris)\rOnce we have this, let’s setup a basic boxplot of some of the features of iris.\nThe iris dataset is built into tidyverse/ggplot2. The dataset is a famous dataset by Edgar Anderson that gives the sepal length, width and petal length and width for three species of iris (n=50).\nWe are going to begin by plotting the sepal length for each species in a basic boxplot.\niris.box \u0026lt;- ggplot(iris, aes(x=Species,y=Sepal.Length)) +\rgeom_boxplot()\riris.box # We have to run a line with the name of the plot object to view the graph. \rSo far, pretty straight forward.\nYou will notice I saved the ggplot() graph to an object called iris.box. Because I saved the plot to an object, I have to run the object name to view the plot. This is identical to using the command print(iris.box).\nNow let’s look at some others, such as a histogram.\niris.hist \u0026lt;- ggplot(iris, aes(x=Sepal.Length)) +\rgeom_histogram()\riris.hist\rThat’s pretty ugly, but a simple addition of binwidth=“value” will fix that. Binwidth refers to the width of each bin, or bar, in the frequency histogram. A bin width of 0.5 means each bar of the histogram will be equal to 0.5 on the x axis (e.g. 4, 4.5, 5, 5.5 etc).\niris.hist \u0026lt;- ggplot(iris, aes(x=Sepal.Length)) +\rgeom_histogram(binwidth = 0.5)\riris.hist\rNow let’s look at a scatterplot.\niris.scatter \u0026lt;- ggplot(iris, aes(x=Sepal.Length,y=Petal.Length)) + geom_point()\riris.scatter\rThe cool thing we can do with scatterplots is colour the points by a categorical feature such as Species. This is done by adding colour = “categorical variable name” in the aes brackets of the ggplot() command.\niris.scatter \u0026lt;- ggplot(iris, aes(x=Sepal.Length, y=Petal.Length, colour=Species)) +\rgeom_point()\riris.scatter\rMuch better. And it even adds a legend for us.\nNow we have this basic setup, we can start adding things to our graph. Due to the immense amount of customisations for our graphs, I will break these down in to sections as much as possible and explain as I go. We will work with the iris dataset for a while before moving to our analysed datasets.\nWrite Ok in the following box to continue:\r{1:SHORTANSWER:=Ok}\n\r\rCustomising your graph\r###Themes \u0026amp; Axis\nThe easiest way to quickly modify your graph is to add one of the preset theme() commands. I will add each of them to the graph which will replace the previous theme.\nWe can simply add items to our current graph object by adding the + sign. Keep in mind that if you dont “resave” it to the object, it wont stick around. If you want to keep a theme, either add it into the original ggplot command, or save it to the same or a new object.\niris.scatter + theme_bw()\riris.scatter + theme_classic()\riris.scatter + theme_dark() \riris.scatter + theme_gray() # The default ggplot theme\riris.scatter + theme_minimal()\riris.scatter + theme_light()\riris.scatter + theme_linedraw()\riris.scatter + theme_void()\rPretty significant changes to the graphs appearance with little effort.\nOf course, we can modify all the individual components of a theme without using one of the presets.\nThe best way to show this would be to look at the ?theme (help) window for this one. The general format for this is as follows.\niris.scatter \u0026lt;- ggplot(iris, aes(x=Sepal.Length, y=Petal.Length, colour=Species)) +\rgeom_point() +\rtheme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = \u0026quot;black\u0026quot;)) + theme(axis.text.x = element_text(colour = \u0026quot;black\u0026quot;, size = 12)) + theme(axis.text.y = element_text(colour = \u0026quot;black\u0026quot;, size = 12)) +\rtheme(plot.title = element_text(color=\u0026quot;blue\u0026quot;, size=12))\riris.scatter\rWithin the theme() command, we simply call the feature we want to change, followed by how we want to change it.\rFor the panel grids and background, we call element_blank() to make it blank. Changing that to element_line() for the grids, and element_rect() for the background would change them to lines and rectangle, respectively. From there we could pick colour, size etc.\nIn the axis.text lines, we are setting the text colour to “black” and the font size to 14.\nNow obviously, this is pretty daunting. But, you dont have to specify everything. You can very easily use one of the above preset themes (e.g. theme_minimal) and change one or two other things, such as axis line colour etc.\nTo save yourself writing all of the above theme() commands everytime you do a graph, you can save your favourite custom settings to its own object and add that to your graphs. Like so:\nsimpletheme \u0026lt;- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = \u0026quot;black\u0026quot;), axis.text.x = element_text(colour = \u0026quot;black\u0026quot;, size = 12), axis.text.y = element_text(colour = \u0026quot;black\u0026quot;, size = 12),plot.title = element_text(color=\u0026quot;blue\u0026quot;, size=12))\r# We simply direct all of our theme arguments to an object\riris.scatter \u0026lt;- iris.scatter + simpletheme # then, just add that object to our graph\rFor example, let’s add those custom theme settings to our boxplot we generated earlier.\niris.box + simpletheme\rOk, so that was alot of information that probably doesn’t make sense, so let’s break that down into its components.\nWrite Ok in the following box to continue:\r{1:SHORTANSWER:=Ok}\nGrids and Background\rThe plot and legend background colours can be changed using the following:\n\rpanel.background = element_rect(insert changes here) - This changes the background of the main plot itself. We need element_rect() as it is a rectangle geometric object.\n\rlegend.background = element_rect(insert changes here) - This will change the main area of the legend.\n\rlegend.key = element_rect(insert changes here) - This will change the small boxes that each of the factors levels are identified with.\r\rFor all arguments, you can replace the element_rect(), element_line() etc. with element_blank() to remove it.\nWithin each of the element_rect() we can change various things. The most common ones are:\n\rfill = “colour” - This will change the overall colour of the object.\rcolour = “colour” - This will change the outline of the rectangle.\rsize = number - This will change the size/thickness of font and lines.\r\rEach of the “colour” arguments can be a specified a number of ways. The most common way is using one of the MANY predefined colours within R. A quick run down of these can be found HERE. For any of these, just put the name as it is spelt in that guide in quotations.\niris.scatter + theme(panel.background = element_rect(fill=\u0026quot;lavender\u0026quot;, colour=\u0026quot;red\u0026quot;), legend.background = element_rect(fill=\u0026quot;lavender\u0026quot;, colour=\u0026quot;yellow\u0026quot;, size=1), legend.key = element_rect(fill = \u0026quot;gray50\u0026quot;, colour = \u0026quot;green\u0026quot;, size = 0.5)) \r\rAxis Lines\rTo change the axis lines and ticks (lines above each number on an axis) use the following.\n\raxis.line = element_line(insert changes here) - This will change both axes lines.\n\raxis.line.x = element_line(insert changes here) - This will change just the x axis.\n\rais.line.y = element_line(insert changes here) - This will change just the y axis.\n\raxis.ticks = element_line(insert changes here) - Change both axes ticks. Use the .x or .y to change just one axis at a time.\n\raxis.ticks.length = element_line(insert changes here) - Change the length of the axes ticks.\n\raxis.text = element_text(insert changes here) - Change the text on the axes TICKS. Use .x or .y to change just one.\n\raxis.title = element_text(insert changes here) - Change the text on the axes LABELS/TITLES. Use .x or .y to change just one.\n\rplot.title = element_text(insert changes here) - Change the plot title.\r\rJust use the colour and size arguments where appropriate. I am going to add these changes as a separate theme() command, but they can be added in the same command as last time.\niris.scatter + theme(panel.background = element_rect(fill=\u0026quot;lavender\u0026quot;, colour=\u0026quot;red\u0026quot;), legend.background = element_rect(fill=\u0026quot;lavender\u0026quot;, colour=\u0026quot;yellow\u0026quot;, size=1), legend.key = element_rect(fill = \u0026quot;gray50\u0026quot;, colour = \u0026quot;green\u0026quot;, size = 0.5)) +\rtheme(axis.line.x = element_line(colour = \u0026quot;skyblue\u0026quot;, size=2), axis.line.y = element_line(colour=\u0026quot;deeppink\u0026quot;, size = 2), axis.title.x = element_text(colour=\u0026quot;forestgreen\u0026quot;, size=14), axis.title.y = element_text(colour = \u0026quot;gold\u0026quot;, size=8), axis.ticks = element_blank())\rBeautiful, isn’t it?\nNow you may have notice the size command acts differently for line and text. For line it is based on a multiplier of the original. So a 2 will be two times its normal size. Element_text() has size as a font size. So 2 would be tiny and equivalent to 2pt font.\rAlternatively, you can use size = rel(number) to scale the text relative to base R’s plotting size.\n\rPanel lines/grids\rSo far, our graph does not have the original ggplot grid lines because we removed them in our original graph. Before we start changing these, let’s save our beautiful masterpiece to an object/variable to simplify the theme() changing.\niris.scatter \u0026lt;- iris.scatter + theme(panel.background = element_rect(fill=\u0026quot;lavender\u0026quot;, colour=\u0026quot;red\u0026quot;), legend.background = element_rect(fill=\u0026quot;lavender\u0026quot;, colour=\u0026quot;yellow\u0026quot;, size=1), legend.key = element_rect(fill = \u0026quot;gray50\u0026quot;, colour = \u0026quot;green\u0026quot;, size = 0.5)) +\rtheme(axis.line.x = element_line(colour = \u0026quot;skyblue\u0026quot;, size=2), axis.line.y = element_line(colour=\u0026quot;deeppink\u0026quot;, size = 2), axis.title.x = element_text(colour=\u0026quot;forestgreen\u0026quot;, size=14), axis.title.y = element_text(colour = \u0026quot;gold\u0026quot;, size=8), axis.ticks = element_blank())\rTo change the grid lines on your plot, it is done with the following:\n\rpanel.grid.major = element_line(insert changes here) - Changes the major grid lines on the graph. Use .x or .y to change just one.\n\rpanel.grid.minor = element_line(insert changes here) - Changes the minor grid lines on the graph. Use .x or .y to change just one.\r\rAgain, using the same principals of colour and size for these ones.\niris.scatter + theme(panel.grid.major = element_line(colour=\u0026quot;aquamarine\u0026quot;, size=1), panel.grid.minor = element_line(colour=\u0026quot;slategray2\u0026quot;, size=2)) \rJust like we did before, we can make all of these our own custom theme by directing them to an object.\nmasterpiece \u0026lt;- theme(panel.background = element_rect(fill=\u0026quot;lavender\u0026quot;, colour=\u0026quot;red\u0026quot;), legend.background = element_rect(fill=\u0026quot;lavender\u0026quot;, colour=\u0026quot;yellow\u0026quot;, size=1), legend.key = element_rect(fill = \u0026quot;gray50\u0026quot;, colour = \u0026quot;green\u0026quot;, size = 0.5), axis.line.x = element_line(colour = \u0026quot;skyblue\u0026quot;, size=2), axis.line.y = element_line(colour=\u0026quot;deeppink\u0026quot;, size = 2), axis.title.x = element_text(colour=\u0026quot;forestgreen\u0026quot;, size=14), axis.title.y = element_text(colour = \u0026quot;gold\u0026quot;, size=8), axis.ticks = element_blank(), panel.grid.major = element_line(colour=\u0026quot;aquamarine\u0026quot;, size=1), panel.grid.minor = element_line(colour=\u0026quot;slategray2\u0026quot;, size=2))\rNow let’s add that to our boxplot.\niris.box + masterpiece\rA true work of art!\n\rLabels\rIf we want to change the axis labels themselves, this is done using the labs() command.\niris.scatter \u0026lt;- iris.scatter + labs(x = \u0026quot;Sepal Length (cm)\u0026quot;, y = \u0026quot;Petal Length (cm)\u0026quot;)\riris.scatter\rIf we wish to add a title to our plot (not overly common in publications) we can use the following.\niris.scatter \u0026lt;- iris.scatter + labs(title= \u0026quot;Relationship between petal and sepal length\u0026quot;) iris.scatter\r\rA Proper example\r## Setting up the graph environment ##\riris.scatter.proper \u0026lt;- ggplot(iris, aes(x=Sepal.Length, y=Petal.Length, colour=Species, shape=Species)) + geom_point()\r## Making our theme ##\rplottheme \u0026lt;- theme(panel.background = element_rect(fill=\u0026quot;ghostwhite\u0026quot;),\rlegend.background = element_blank(),\rlegend.key = element_rect(fill=\u0026quot;ghostwhite\u0026quot;),\raxis.line = element_line(colour=\u0026quot;black\u0026quot;, size=1),\raxis.ticks = element_blank(),\raxis.title = element_text(colour=\u0026quot;royalblue3\u0026quot;, size=14),\rplot.title = element_text(face=\u0026quot;bold\u0026quot;, colour=\u0026quot;steelblue4\u0026quot;, size=16),\rlegend.title = element_text(colour=\u0026quot;royalblue3\u0026quot;, size=14),\rlegend.text = element_text(face=\u0026quot;italic\u0026quot;, colour=\u0026quot;steelblue4\u0026quot;, size=10),\raxis.text = element_text(colour=\u0026quot;steelblue4\u0026quot;, size=12),\rpanel.grid.major = element_line(colour=\u0026quot;gray80\u0026quot;),\rpanel.grid.minor = element_blank())\r## Applying the theme, adding some labels and changing some colours ##\riris.scatter.proper \u0026lt;- iris.scatter.proper + plottheme +\rlabs(x=\u0026quot;Sepal Length (cm)\u0026quot;, y=\u0026quot;Petal Length (cm)\u0026quot;, title=\u0026quot;Relationship between Sepal Length and Petal Length\u0026quot;) +\rscale_colour_manual(values = c(\u0026quot;mediumorchid1\u0026quot;, \u0026quot;mediumorchid3\u0026quot;, \u0026quot;mediumorchid4\u0026quot;))\r## Displaying our graph ##\riris.scatter.proper\rPretty cool example of changing things around for the “better”. You might notice a few extra things I have changed in this graph.\nIn the aes() section at the start, I introduced the shape command which changes the shape for each level of a factor. Doing this alongside colour= allows us to change the colour and symbol of the points themselves.\nFurther down, I then changed the colour of the points using scale_colour_manual() and adding the colour values for the levels in order. There are many different ways you can do this, but I find this works the best. There are scale_manual commands for fill, group, shape etc.\nIn the theme() section, I covered most things we have done so far but added an additional argument to legend.text and plot.title. This is the face argument which allows us to add italics, bold or others to our text.\nWrite Ok in the following box to continue:\r{1:SHORTANSWER:=Ok}\n\r\rPlotting our analysed data\rHopefully by now, we understand the general principals of ggplot and how to heavily customise the appearance. Now, lets start plotting our analysed data.\nWeeds (ANOVA bar graph)\rOur first data set we analysed was the weeds dataset where we performed a two-factor ANOVA.\nweeds.aov2 \u0026lt;- aov(flowers ~ species * soil, data = weeds)\ranova(weeds.aov2)\r## Analysis of Variance Table\r## ## Response: flowers\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## species 2 2368.6 1184.31 9.1016 0.0005203 ***\r## soil 1 238.5 238.52 1.8331 0.1830080 ## species:soil 2 155.0 77.52 0.5958 0.5557366 ## Residuals 42 5465.1 130.12 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rFrom this, only Species was significant. For this dataset with a continuous Y and categorical X we would plot a bargraph.\nThe best way to generate the bargraph properly, is to use the *summarise()** command to generate our means and standard errors before plotting. We can generate these within the ggplot command, but it can lead to complications.\nweeds.summarise \u0026lt;- weeds %\u0026gt;% group_by(species) %\u0026gt;%\rsummarise(mean = mean(flowers), se=sd(flowers/sqrt(n())))\rThis is a quick way to generate our mean and se for flowers for each species. Now, we can graph our results in a bargraph.\nweeds.col \u0026lt;- ggplot(weeds.summarise, aes(x=species, y=mean, fill=species)) +\rgeom_col()\rweeds.col\rThis will generate a pretty basic graph. You will notice that I used fill instead of colour. If you use colour on a column/bar graph it will only do the outline. Using fill will fill the entire bar according to the species.\nWe used geom_col() to generate a column graph. You can use geom_bar() but it requires a stat = argument. If you use geom_bar() try stat = “identity” to use the numbers in the mean column of our data.\nI would reccomend geom_bar() as it is easier to do errorbars later\nweeds.bar \u0026lt;- ggplot(weeds.summarise, aes(x=species, y=mean, fill=species)) +\rgeom_bar(stat=\u0026quot;identity\u0026quot;)\rweeds.bar\rRegardless of what way you graph this, they look the same. For now, let’s work with the geom_col(). Let’s fix up the graph as much as we want, until we are happy. To demonstrate this, I will produce the graph without showing the code and you can customise your graph how you see fit.\nSo, now we have our graph in a “nicer” format, we can see that there are some cruical points of information missing from this graph. Most notably, the errorbars and letters or some other notation that denotes statistical differences between the levels (Tukeys results).\nNote: To remove the legend like I have, include the show.legend argument in your geom_bar() command and set it to false. e.g. geom_bar(stat=“identity”, show.legend=F)\nTo add the error bars, we use the following command\nweeds.bar \u0026lt;- weeds.bar + geom_errorbar(aes(ymin = mean-se, ymax = mean+se), width=0.5)\rweeds.bar\rThis is suprisingly simple. All we do is specify the aesthetic (aes) where we compute our minimum and maximum y values for our bars as our mean column +/- our standard error column. The width argument is how wide we want our error bars to be. A size argument can be added to make the lines thicker if needed. Try modifying the value on width to see how it works, 0.9 is the default.\nAdding Tukeys test results is simple but slightly tedious once we have the results.\nlibrary(agricolae)\rHSD.test(weeds.aov2, \u0026quot;species\u0026quot;, console=TRUE)\r## ## Study: weeds.aov2 ~ \u0026quot;species\u0026quot;\r## ## HSD Test for flowers ## ## Mean Square Error: 130.122 ## ## species, means\r## ## flowers std r Min Max\r## Coprosma 24.1250 11.13478 16 13 52\r## Olearia 36.7500 12.08580 16 16 55\r## Pultenaea 40.5625 10.97858 16 20 57\r## ## Alpha: 0.05 ; DF Error: 42 ## Critical Value of Studentized Range: 3.435823 ## ## Minimun Significant Difference: 9.798198 ## ## Treatments with the same letter are not significantly different.\r## ## flowers groups\r## Pultenaea 40.5625 a\r## Olearia 36.7500 a\r## Coprosma 24.1250 b\rAccording to the tukeys results, Coprosma is significantly different from the others. So we will label it A and the others B.\nweeds.bar \u0026lt;- weeds.bar + geom_text(label = c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;B\u0026quot;), aes(y = c(28.5, 41, 44.5), x = species), size = 6)\r# try including the geom_text() in your original weeds.bar code. # if you keep adding it like this, the letters will stack and it will be a mess.\rweeds.bar\rAdding the letters is done through geom_text(). We need to specify the labels (in order) along with the aesthetic coordinates on the x and y axis. The X axis we can direct it to our original x axis data (species) and it will sit in the centre of the column. The Y coordinates are the location on the Y axis the text should sit.\nThis requires alot of playing around to get them correct so I would advise doing this when you first setup the graph. If you don’t, and keep re-running the geom_text() commands, you can end up with multiple letters.\nThere is an alternative to setting the coordinates manually.\n# Note: I have reset my weeds.bar to remove the previous letters posthoc \u0026lt;- HSD.test(weeds.aov2, \u0026quot;species\u0026quot;, console=TRUE)\r## ## Study: weeds.aov2 ~ \u0026quot;species\u0026quot;\r## ## HSD Test for flowers ## ## Mean Square Error: 130.122 ## ## species, means\r## ## flowers std r Min Max\r## Coprosma 24.1250 11.13478 16 13 52\r## Olearia 36.7500 12.08580 16 16 55\r## Pultenaea 40.5625 10.97858 16 20 57\r## ## Alpha: 0.05 ; DF Error: 42 ## Critical Value of Studentized Range: 3.435823 ## ## Minimun Significant Difference: 9.798198 ## ## Treatments with the same letter are not significantly different.\r## ## flowers groups\r## Pultenaea 40.5625 a\r## Olearia 36.7500 a\r## Coprosma 24.1250 b\r# we save this so we can call on it to do our letters. This will also work for a normal \u0026quot;non-agricolae\u0026quot; tukeys, but will be called something different in the dataframe\rweeds.bar \u0026lt;- weeds.bar + geom_text(label = posthoc$groups$groups, aes(y=mean+se, x=species), vjust=-0.5, size=6) + ylim(0, 50)\rweeds.bar\rIn this example, we pull the lettering from our posthoc tukeys test after saving it to a dataframe. We then specify our Y coordinates as the top of our error bar and use the vjust argument to move it slightly above the bar. This means we also had to change our ylim to display the last letter, which got cut off.\nThis seems like alot more work, but when you have a lot more bars…you will thank me\nThats the general process for setting up a column graph for ANOVA data. It can take some time, but we get alot of freedom in how we present this.\nOnce we are satisfied with our final product, we can save it as a image file to our current working directory. Simply plot the graph again, by calling the object name, then use the ggsave() command like so.\nweeds.bar #producing the graph again\rggsave(\u0026quot;weeds_bargraph.jpeg\u0026quot;) # specify the name and filetype (.jpeg, .png etc.). You can also specify the width and heigh of your final image\rggsave() will save the last plot you produced into your current working directory. You need to specify the name (in my case “weeds_bargraph”) and the filetype (.jpeg in my example). By default, it should save a 7 cm x 7cm image. If you want to change that, use the width = or height = arguments, like so. For higher resolution images, try .png or .tif\nggsave(\u0026quot;weeds_bargraph.jpeg\u0026quot;, width=9, height=7)\rI wanted a slightly wider figure but it’s personal preference.\nPlotting multiple columns\rIn the last example, we plotted a single column graph. To plot multiple columns, for example a soil by species interaction, is quite simple.\nweeds.summarise2 \u0026lt;- weeds %\u0026gt;% group_by(species, soil) %\u0026gt;%\rsummarise(mean = mean(flowers), se=sd(flowers/sqrt(n())))\rweeds.bar2 \u0026lt;- ggplot(weeds.summarise2, aes(x=soil, y=mean, fill=species)) +\rgeom_bar(stat=\u0026quot;identity\u0026quot;)\rweeds.bar2\rSimply specifying one column from our dataset on the x axis, and filling/colouring by another will plot both of the data. However, you can see the bar graph has stacked the species ontop of one another. To fix this, include the position=position_dodge() argument in your geom_bar(), like so.\nweeds.bar2 \u0026lt;- ggplot(weeds.summarise2, aes(x=soil, y=mean, fill=species)) + geom_bar(stat=\u0026quot;identity\u0026quot;, position=position_dodge())\rweeds.bar2\rNOTE: You will need to include the position=position_dodge() in your errorbar code. I have had a lot of issues with dodged bargraphs and error bars…so it can get a little finicky.\nWrite Ok in the following box to continue:\r{1:SHORTANSWER:=Ok}\n\r\rTadpoles (linear regression)\rIn our second dataset, we analysed tadpole abundance in different sized ponds using a linear model/regression.\ntadpoles.lm \u0026lt;- lm(abundance ~ pondsize, data = tadpoles)\rsummary(tadpoles.lm)\r## ## Call:\r## lm(formula = abundance ~ pondsize, data = tadpoles)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -73.546 -29.752 -8.026 37.978 77.652 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 23.8251 25.8455 0.922 0.36662 ## pondsize 1.7261 0.5182 3.331 0.00303 **\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 49.42 on 22 degrees of freedom\r## Multiple R-squared: 0.3352, Adjusted R-squared: 0.305 ## F-statistic: 11.09 on 1 and 22 DF, p-value: 0.003032\rFor this, we will be setting up a scatter plot (geom_point) of our points and then adding the line separately.\ntadpoles.scatter \u0026lt;- ggplot(tadpoles, aes(x=pondsize, y=abundance)) +\rgeom_point()\rtadpoles.scatter\rThats our basic scatter plot. Thankfully, doing a simple linear regression on ggplot is super simple.\ntadpoles.scatter + stat_smooth(method = lm)\rThe stat_smooth() will produce a line of best fit, along with the confidence intervals based on the method of fit we choose. If we choose linear model (lm) it will construct a linear model of our Y variable by the X variable.\nIf you dont want the shaded confidence intervals, simply add the argument, se=FALSE within the brackets.\ntadpoles.scatter \u0026lt;- ggplot(tadpoles, aes(x=pondsize, y=abundance)) +\rgeom_point() +\rstat_smooth(method=lm, se=FALSE)\rtadpoles.scatter\rWe can also add multiple lines, based on a factor using the colour argument.\ntadpoles.scatter2 \u0026lt;- ggplot(tadpoles, aes(x=pondsize, y=abundance, colour=reeds)) +\rgeom_point() +\rstat_smooth(method=lm, se=FALSE)\rtadpoles.scatter2\rNotice that they stop within the range of the points. To extend these use fullrange=TRUE. Use this cautiously, as it extrapolates the current relationship past your datapoints.\ntadpoles.scatter2 \u0026lt;- ggplot(tadpoles, aes(x=pondsize, y=abundance, colour=reeds)) +\rgeom_point() +\rstat_smooth(method=lm, se=FALSE, fullrange=TRUE)\rtadpoles.scatter2\rWrite Ok in the following box to continue:\r{1:SHORTANSWER:=Ok}\n\rNest Dataset (Logistic Regression/GLM)\rIn our third dataset, we analysed the nest predation dataset using a generalised linear model with a binomial distribution, also known as a Logistic Regression.\nIn this scenario, our data is measuring whether a nest was attacked or not in areas of different shrubcover. When we analyse this using a GLM, it is calculating the probability of a nest being attacked, given different values of shrubcover. As such, we need to plot this in a similar manner.\nFirst let’s demonstrate what happens when we don’t take the binomial distribution into account.\nnest.wrong \u0026lt;- ggplot(nest, aes(x=shrubcover, y=nestattacked)) + geom_point()\rnest.wrong\rNotice how it has plotted the points at either 0 or 1 for each of the corresponding shrubcover values. This does not tell us anything about the likelihood of a nest being attacked given a value of shrubcover.\nThere are multiple methods for producing this plot. The one we will be using generates the relationship between our variables in the code itself.\nnest.smooth \u0026lt;- ggplot(nest,aes(x=shrubcover, y=nestattacked)) +\rgeom_smooth(method = glm, method.args= list(family=\u0026quot;binomial\u0026quot;))\rnest.smooth\rThis method utilises the geom_smooth() function we were using for our linear model. This time we specify the glm relationship in the method argument, instead of lm. We also need to include a second argument called method.args which stands for method arguments, or, additional arguments for the method we have specified. We need to include this so we can inform our code that our distribution (family) is binomial. By including this, we produce our probability curve\nWe can also choose, much like our linear regression example, to remove our standard error/confidence intervals by using the se=FALSE argument rather than the default se=TRUE.\nnest.smooth \u0026lt;- ggplot(nest,aes(x=shrubcover, y=nestattacked)) +\rgeom_smooth(method = glm, method.args= list(family=\u0026quot;binomial\u0026quot;), se=FALSE)\rnest.smooth\rThis is not necassarily “the best” method but it is by far the easiest.\nWrite Ok in the following box to continue:\n{1:SHORTANSWER:=Ok}\n\r\r"
},
{
	"uri": "/statistical-analysis/3_anovaresults/",
	"title": "ANOVA Results",
	"tags": [],
	"description": "",
	"content": "3. Results\rOnce we know our data is normal and we have our aov() object, we can use one of two commands on this object to generate our statistical result. The normal way to do so is to use the anova() command.\nanova(weeds.aov) # run an anova on the object\r## Analysis of Variance Table\r## ## Response: flowers\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## species 2 2368.6 1184.31 9.0966 0.0004811 ***\r## Residuals 45 5858.7 130.19 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r# WOO! Significance!\rAlternatively we can use the summary() command on our aov() object to generate the same result. For most other analyses, such as linear regressions and mixed models, we will use the summary command exclusively.\nBecause we created an aov() object, the summary() command automatically does an ANOVA.\nsummary(weeds.aov) # print a summary of the object. In this case the summary is an anova\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## species 2 2369 1184.3 9.097 0.000481 ***\r## Residuals 45 5859 130.2 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rUsing the summary() command, what is the F-value for fragment in the Insecticide ANOVA?\n{1:SHORTANSWER:=14.94}\n\r"
},
{
	"uri": "/statistical-analysis/4_twofactors/",
	"title": "Two-factor Analysis of Variance",
	"tags": [],
	"description": "",
	"content": "4. Two-factors and Transformations\rTo conduct an two-factor ANOVA is pretty straightforward.\nweeds.aov2 \u0026lt;- aov(flowers ~ species + soil, data = weeds) # two-factor anova (without interaction)\rsummary(weeds.aov2)\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## species 2 2369 1184.3 9.272 0.000436 ***\r## soil 1 239 238.5 1.867 0.178720 ## Residuals 44 5620 127.7 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rThis example constructs an ANOVA with two factors, but does not include the interaction term. If we want the interaction term, simply replace the + sign with an asterisk * .\nweeds.aov2 \u0026lt;- aov(flowers ~ species * soil, data = weeds) # two-factor anova (with interaction)\rsummary(weeds.aov2)\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## species 2 2369 1184.3 9.102 0.00052 ***\r## soil 1 239 238.5 1.833 0.18301 ## species:soil 2 155 77.5 0.596 0.55574 ## Residuals 42 5465 130.1 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rIncluding the asterisk tells the formula to multiply both of the factors creating the interaction factor. It will automatically produce the results for factors independantly as well as the interaction term.\nDon’t forget to check your assumptions\nEverything stays the same for assumptions except the following modifications to Bartlett’s and Levene’s Tests.\nbartlett.test(flowers ~ interaction(species, soil), data = weeds) # Add the interaction() argument to correctly analyse an interaction term\r## ## Bartlett test of homogeneity of variances\r## ## data: flowers by interaction(species, soil)\r## Bartlett\u0026#39;s K-squared = 5.3304, df = 5, p-value = 0.3769\rleveneTest(flowers ~ species * soil, data = weeds) # same syntax as the normal formula\r## Levene\u0026#39;s Test for Homogeneity of Variance (center = median)\r## Df F value Pr(\u0026gt;F)\r## group 5 0.81 0.5492\r## 42\rTransformations\nThere are two methods to transform your response (Y) variable for an analysis.\nUse a data manipulation technique such as mutate() to create a new column; or\rTransform the variable within the analysis formula (see below)\r\rFor this example, we will be log transforming the flowers column within the weeds dataset.\nNOTE: THIS MAKES NO SENSE AS IT IS NORMAL. IT IS JUST AN EXAMPLE!\n## Mutate Option ##\rweeds \u0026lt;- mutate(weeds, logflowers = log(flowers)) # create new column called \u0026quot;logflowers\u0026quot;\r## Formula option ##\rweeds.aov.log \u0026lt;- aov(log(flowers) ~ species * soil, data = weeds) # log(flowers) as our Y variable tells the anova to use a log transformed response.\rsummary(weeds.aov.log)\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## species 2 2.842 1.4211 11.158 0.00013 ***\r## soil 1 0.239 0.2387 1.874 0.17831 ## species:soil 2 0.247 0.1234 0.969 0.38792 ## Residuals 42 5.349 0.1274 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rRemember\nIf you are testing assumptions, you must run the aov() (or general analysis) again with the new transformation and then extract residuals.\nshapiro.test(log(weeds.aov$residuals)) #### DO NOT DO THIS!! ####\r## ## Shapiro-Wilk normality test\r## ## data: log(weeds.aov$residuals)\r## W = 0.95759, p-value = 0.4422\rshapiro.test(weeds.aov.log$residuals) # Do this! #\r## ## Shapiro-Wilk normality test\r## ## data: weeds.aov.log$residuals\r## W = 0.97792, p-value = 0.4951\rSee how those are different? The same thing applies to square root (sqrt) or square/cubic transformations (^2, ^3).\nConstruct a Two-factor ANOVA (with interaction) on the Insecticide dataset and answer the following:\n1. Is the data normal?\n{1:MULTICHOICE:Yes #Wrong~=No #OK}\n2. What is the p-value for the Bartlett’s test?\n{1:SHORTANSWER:=0.1339}\n3. Without transforming to normalise, what is the p-value for the interaction term?\n{1:SHORTANSWER:=0.03275}\n\r"
},
{
	"uri": "/the-grammar-of-graphics/",
	"title": "The Grammar of Graphics",
	"tags": [],
	"description": "",
	"content": "Hugo uses Markdown for its simple content format. However, there are a lot of things that Markdown doesn’t support well. You could use pure HTML to expand possibilities.\nBut this happens to be a bad idea. Everyone uses Markdown because it\u0026rsquo;s pure and simple to read even non-rendered. You should avoid HTML to keep it as simple as possible.\nTo avoid this limitations, Hugo created shortcodes. A shortcode is a simple snippet inside a page.\nHugo-theme-learn provides multiple shortcodes on top of existing ones.\n The Grammer of Graphics - Plotting your data with ggplot!  Resources\rThe Grammar of ggplot\rBasic plots\rCustomising your graph\rGrids and Background\rAxis Lines\rPanel lines/grids\rLabels\rA Proper example\rPlotting our analysed data\rWeeds (ANOVA bar graph)\rTadpoles (linear regression)\rNest Dataset (Logistic Regression/GLM)\rBy now you should be fairly familiar with the R environment and decently familiar with tidyverse. You should be able to perform basic data manipulations, analyses and in general, understand the general concepts of working with data in R.\n "
},
{
	"uri": "/statistical-analysis/5_tukeys/",
	"title": "Tukeys HSD",
	"tags": [],
	"description": "",
	"content": "5. Tukey’s HSD\rAll of our analyses so far have showed us that species has an influence on flower abundance. But without conducting an extra test, we cannot be certain which species are statistically significant from each other when it comes to their effect on flower abundance\nTukeyHSD(weeds.aov) \r## Tukey multiple comparisons of means\r## 95% family-wise confidence level\r## ## Fit: aov(formula = flowers ~ species, data = weeds)\r## ## $species\r## diff lwr upr p adj\r## Olearia-Coprosma 12.6250 2.84785 22.40215 0.0084638\r## Pultenaea-Coprosma 16.4375 6.66035 26.21465 0.0005330\r## Pultenaea-Olearia 3.8125 -5.96465 13.58965 0.6149669\rThis is showing us whether the two compared means are significantly different from each other (p adj).\nThis will give us the print out for the whole analysis. If we want only one factor to be displayed, simply include the which =  agument and specify what factor\nTukeyHSD(weeds.aov, which = \u0026quot;species\u0026quot;) # this will give us only the species column\r## Tukey multiple comparisons of means\r## 95% family-wise confidence level\r## ## Fit: aov(formula = flowers ~ species, data = weeds)\r## ## $species\r## diff lwr upr p adj\r## Olearia-Coprosma 12.6250 2.84785 22.40215 0.0084638\r## Pultenaea-Coprosma 16.4375 6.66035 26.21465 0.0005330\r## Pultenaea-Olearia 3.8125 -5.96465 13.58965 0.6149669\rWhile handy and quick, its hard to interpret the print out of this test, particularly in analyses with multi-leveled factors.\nThe following Tukeys HSD test comes from the package agricolae. I personally only use this package for the Tukeys HSD letter report function.\nlibrary(agricolae)\rHSD.test(weeds.aov, \u0026quot;species\u0026quot;, console=TRUE) # HSD.test() requires you to state the factor, as well as print the output to the console (console=TRUE)\r## ## Study: weeds.aov ~ \u0026quot;species\u0026quot;\r## ## HSD Test for flowers ## ## Mean Square Error: 130.1931 ## ## species, means\r## ## flowers std r Min Max\r## Coprosma 24.1250 11.13478 16 13 52\r## Olearia 36.7500 12.08580 16 16 55\r## Pultenaea 40.5625 10.97858 16 20 57\r## ## Alpha: 0.05 ; DF Error: 45 ## Critical Value of Studentized Range: 3.427507 ## ## Minimun Significant Difference: 9.77715 ## ## Treatments with the same letter are not significantly different.\r## ## flowers groups\r## Pultenaea 40.5625 a\r## Olearia 36.7500 a\r## Coprosma 24.1250 b\rAs mentioned, this specific Tukey’s function can only do a single specified factor (to my knowledge). These Tukey’s tests are options for single factor significance. For an interaction significance, you will need to consider alternative post-hoc methods.\nAn interesting method of visualising the interaction term is using the interaction.plot() command. Specifying the three columns you want to see.\ninteraction.plot(weeds$species, weeds$weeds, weeds$flowers)\rIn this example, we see the increase in number of flowers, with a markedly higher increase in native. The significant increase in species is only present in Oleria in native areas.\nWrite Ok in the following box to continue:\n{1:SHORTANSWER:=Ok}\n\r"
},
{
	"uri": "/statistical-analysis/6_linearregession/",
	"title": "Linear Regression",
	"tags": [],
	"description": "",
	"content": "6. Linear Regression\rLinear regression is one of the most highly used statistical techniques in all of life and earth sciences. It is used to model the relationship between a response (Y) variable and a explanatory (X) variable. A linear regression is a special case of a linear model whereby both the response and explanatory variables are continuous. The ANOVA we just conducted is still considered as a linear model since the response variable is a linear (additive) combination of the effects of the explanatory variables.\nSince we have already conducted an ANOVA, a linear model will be a peice of cake!\nFor this, we will be using the tadpoles.csv dataset.\nstr(tadpoles) # three columns, all continuous\r## \u0026#39;data.frame\u0026#39;: 24 obs. of 3 variables:\r## $ reeds : int 1 1 1 1 1 1 1 1 2 2 ...\r## $ pondsize : int 45 60 20 45 56 16 37 49 50 16 ...\r## $ abundance: int 120 201 136 128 178 55 156 150 89 25 ...\rAutomatically, upon reading the tadpoles dataset, we have an issue. Our reeds column should actually be a category, so we need to read that in as a factor.\nMake reeds into a factor\nOnce everything is input correctly, we can begin our analysis\ntadpoles.lm \u0026lt;- lm(abundance ~ pondsize, data = tadpoles) # constructing a linear model\rThe lm() command creates a linear model object. In this example we are testing the effect of pondsize on tadpole abundance using a linear regression.\nIt is worth noting that the lm() command can be used to perform an anova, but the aov() command cannot be used for regressions. Give it a try by using lm on our last analysis and use the anova command, as well as the summary() command on the created object.\nsummary(tadpoles.lm) # summarising the newly created linear model object\r## ## Call:\r## lm(formula = abundance ~ pondsize, data = tadpoles)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -73.546 -29.752 -8.026 37.978 77.652 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 23.8251 25.8455 0.922 0.36662 ## pondsize 1.7261 0.5182 3.331 0.00303 **\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 49.42 on 22 degrees of freedom\r## Multiple R-squared: 0.3352, Adjusted R-squared: 0.305 ## F-statistic: 11.09 on 1 and 22 DF, p-value: 0.003032\rThe estimates for the coefficients give you the slope and the intercept (much like JMP). In this example, the regression equation would be:\nAbundance = 23.8251 + 1.7261*pondize + error\nThe summary() printout gives us a lot of useful information, so we need to narrow down what is most important. The t-value and p-value for each coefficient indicate significance. We dont really care about the intercept. What we do care about is if the other coefficient (pondsize) is significant, indicating an effect of the explanatory variable on the reponse. Because of the positive estimate (1.7261) we can identify that an increase in pondsizeis associated with a significant increase in tadpole abundance.\nWhile the t and p values indicate a significant association, the R^2 value tells us the strength of the association. In this case, the proportion of variation explained by the explanatory variable is 33.52%.\n\rAssumptions\rTo test assumptions for linear regression, we need to test the same assumptions we tested for the ANOVA. The only slight exception here is the pattern/appearance of the residuals in the fitted v.s residuals plot AND, we cant use bartlett’s or levene’s tests.\nplot(tadpoles.lm, 1)\rIn this plot we are looking for an even “shotgun” like appearance in the residuals. We want an even dispersal around the grand mean. In this example, we have a spread of redisuals that does not appear to follow any non-linear trends. There is no point trying to fit a straight line through data that is curved. If there is strong patterning in your residuals, try log-transforming your response or, fit a polynomial function (e.g. quadratic).\nClick the link below to see a nice interactive app that demonstrates what patterns of residuals you would expect with linear and curved relationships:\nLinear regression diagnostics\rhttps://gallery.shinyapps.io/slr_diag/\nTest your normality before moving on.\nWrite Ok in the following box to continue:\n{1:SHORTANSWER:=Ok}\n\r"
},
{
	"uri": "/statistical-analysis/7_glms/",
	"title": "ANOVA assumptions",
	"tags": [],
	"description": "",
	"content": "7. Generalised Linear Models (GLMs)\rSo far, we have been using linear models which assume that our response variable is continuous. In earth and life sciences (ecology in particular) we are often working with discrete data, such as count data and binomial (presence/absence) data.\nThe linear models we have been using so far have been assuming a normal (or gaussian) distribution in our data. Generalised linear models (GLMs) allow us to fit alternative distributions to our data in order to more accurately analyse them.\nGLMs do make some important assumptions which we will need to check when we construct the model.\nOur binomial (logistic regression) does have some assumptions, but thankfully it is fairly resiliant and we dont need to test them. For any other distribution (poisson, gamma etc.) these are cruical.\nIt is important to note that part of fitting a GLM is using a link function. I won’t be explaining these in detail, all you need to know is the default link method for binomial data is the logit() method. For more information see ?family.\nFor this analysis, we will be using the nestpredation.csv dataset\nstr(nest) # view the structure\r## \u0026#39;data.frame\u0026#39;: 20 obs. of 2 variables:\r## $ shrubcover : int 16 20 11 15 19 31 5 12 9 10 ...\r## $ nestattacked: int 1 0 1 1 1 0 1 1 1 0 ...\r# This is okay. Our nest attacked column is an integer, but the glm will tell it to input as binomial so we dont need to change anything. nest.bin\u0026lt;-glm(nestattacked~shrubcover, data=nest, family=binomial)\rThe glm() commands follows the same structure as the lm() and aov() with the inclusion of the extra argument family. Family is where we specify our distribution. In this case, for our logistic regression, we specify a binomial distribution.\nOnce we have constructed our model, we can use the anova() command and the summary() commands to look at our results. The summary() commands p-values tend to be a little weird, so I prefer to use the anova() command to look at variable significance, and summary() to look at the model equation if I need it.\nanova(nest.bin, test=\u0026quot;Chisq\u0026quot;) # anova test using a chisq instead of F\r## Analysis of Deviance Table\r## ## Model: binomial, link: logit\r## ## Response: nestattacked\r## ## Terms added sequentially (first to last)\r## ## ## Df Deviance Resid. Df Resid. Dev Pr(\u0026gt;Chi) ## NULL 19 27.526 ## shrubcover 1 9.0911 18 18.434 0.002569 **\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rThere is strong evidence that the probability of a nest being attacked varies with shrubcover (p\u0026lt;0.01).\nsummary(nest.bin)\r## ## Call:\r## glm(formula = nestattacked ~ shrubcover, family = binomial, data = nest)\r## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.8424 -0.5183 -0.2135 0.8024 1.5148 ## ## Coefficients:\r## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) 3.3782 1.6025 2.108 0.035 *\r## shrubcover -0.1883 0.0857 -2.198 0.028 *\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## (Dispersion parameter for binomial family taken to be 1)\r## ## Null deviance: 27.526 on 19 degrees of freedom\r## Residual deviance: 18.434 on 18 degrees of freedom\r## AIC: 22.434\r## ## Number of Fisher Scoring iterations: 5\rLook at the differences in this table and the anova table. It’s hard to understand what is happening here and doesn’t provide you with the overall model effects, in most cases.\nWrite Ok in the following box to continue:\n{1:SHORTANSWER:=Ok}\n\r"
},
{
	"uri": "/datasets/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "  Data Sets   frog_environmental.csv  (2 ko)   frogs.csv  (1 ko)   insecticide.csv  (0 ko)   nestpredation.csv  (0 ko)   site.csv  (0 ko)   tadpoles.csv  (0 ko)   weeds.csv  (1 ko)    "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/ggplot/",
	"title": "Ggplot",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/r/",
	"title": "R",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/",
	"title": "R Statistics for Ecologists",
	"tags": [],
	"description": "",
	"content": " Ecostatistics "
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]